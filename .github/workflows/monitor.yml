name: Production Error Monitor

on:
  schedule:
    # Run every hour
    - cron: "0 * * * *"
  workflow_dispatch: # Allow manual trigger from GitHub UI

jobs:
  monitor:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write
      issues: write

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: npm

      # Step 1: Fetch Vercel runtime logs and push them into centralized blob logs
      - name: Ingest Vercel runtime logs
        id: ingest
        env:
          VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }}
          VERCEL_PROJECT_ID: prj_W31dDW0Ekdsn4G3Ufz4VxPEg8a9s
          VERCEL_TEAM_ID: team_K5YfQm6u9dAQGJT6txaCOmoF
          LOG_API_SECRET: ${{ secrets.LOG_API_SECRET }}
          BASE_URL: https://www.meantforgreatness.org
        run: |
          # Get the latest production deployment
          DEPLOYMENTS=$(curl -s -H "Authorization: Bearer $VERCEL_TOKEN" \
            "https://api.vercel.com/v6/deployments?projectId=$VERCEL_PROJECT_ID&teamId=$VERCEL_TEAM_ID&target=production&limit=1&state=READY")

          DEPLOYMENT_ID=$(echo "$DEPLOYMENTS" | jq -r '.deployments[0].uid // empty')

          if [ -z "$DEPLOYMENT_ID" ]; then
            echo "Could not find a production deployment."
            echo "ingested=0" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          DEPLOYMENT_URL=$(echo "$DEPLOYMENTS" | jq -r '.deployments[0].url // empty')
          echo "Latest deployment: $DEPLOYMENT_ID ($DEPLOYMENT_URL)"

          # Fetch runtime logs for this deployment
          RAW_LOGS=$(curl -s -H "Authorization: Bearer $VERCEL_TOKEN" \
            "https://api.vercel.com/v2/deployments/$DEPLOYMENT_ID/events?teamId=$VERCEL_TEAM_ID&limit=500&direction=backward" 2>/dev/null || true)

          if [ -z "$RAW_LOGS" ] || [ "$RAW_LOGS" = "[]" ] || [ "$RAW_LOGS" = "null" ]; then
            echo "No Vercel logs to ingest."
            echo "ingested=0" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          # Extract error entries from Vercel logs
          ERRORS=$(echo "$RAW_LOGS" | jq -c '[.[] | select(.type == "stderr" or .type == "error" or (.text // "" | test("(?i)(error|ERR|500|exception|unhandled|fatal|TypeError|ReferenceError)"))) | {message: (.text // .message // ""), type: .type}]' 2>/dev/null || echo "[]")

          ERROR_COUNT=$(echo "$ERRORS" | jq 'length')

          if [ "$ERROR_COUNT" = "0" ]; then
            echo "No Vercel errors to ingest."
            echo "ingested=0" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          echo "Found $ERROR_COUNT Vercel runtime errors. Ingesting into centralized logs..."

          # Build entries array for the ingest API
          ENTRIES=$(echo "$ERRORS" | jq -c '[.[] | {level: "error", source: "vercel:runtime", message: .message, meta: {type: .type, deployment: "'"$DEPLOYMENT_ID"'"}}]')

          # Push to centralized logs via ingest API
          RESULT=$(curl -sf -X POST \
            -H "Authorization: Bearer $LOG_API_SECRET" \
            -H "Content-Type: application/json" \
            -d "{\"entries\": $ENTRIES}" \
            "$BASE_URL/api/admin/logs/ingest" 2>/dev/null || echo "")

          if [ -n "$RESULT" ]; then
            INGESTED=$(echo "$RESULT" | jq '.ingested // 0')
            echo "Ingested $INGESTED Vercel runtime errors into centralized logs."
            echo "ingested=$INGESTED" >> "$GITHUB_OUTPUT"
          else
            echo "Failed to ingest Vercel logs (API may be unreachable)."
            echo "ingested=0" >> "$GITHUB_OUTPUT"
          fi

      # Step 2: Wait briefly for ingested logs to be available
      - name: Wait for log propagation
        if: steps.ingest.outputs.ingested != '0'
        run: sleep 3

      # Step 3: Check centralized logs â€” the SINGLE source of truth
      - name: Check centralized logs for errors
        id: check
        env:
          LOG_API_SECRET: ${{ secrets.LOG_API_SECRET }}
          BASE_URL: https://www.meantforgreatness.org
        run: |
          SINCE=$(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ 2>/dev/null || date -u -v-1H +%Y-%m-%dT%H:%M:%SZ 2>/dev/null || echo "")

          if [ -z "$LOG_API_SECRET" ]; then
            echo "LOG_API_SECRET not configured â€” skipping."
            echo "has_errors=false" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          LOGS=$(curl -sf -H "Authorization: Bearer $LOG_API_SECRET" \
            "$BASE_URL/api/admin/logs?level=error&since=$SINCE&limit=100" 2>/dev/null || echo "")

          if [ -z "$LOGS" ]; then
            echo "Could not fetch centralized logs (API may be unreachable)."
            echo "has_errors=false" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          ERROR_COUNT=$(echo "$LOGS" | jq '.pagination.total // 0' 2>/dev/null || echo "0")

          if [ "$ERROR_COUNT" = "0" ]; then
            echo "No errors in centralized logs. All clear. âœ…"
            echo "has_errors=false" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          echo "Found $ERROR_COUNT errors in centralized logs."

          # Format errors for the issue
          echo "$LOGS" | jq -r '.data[] | "\(.timestamp) [\(.source)] \(.message)"' > /tmp/errors.txt
          echo "has_errors=true" >> "$GITHUB_OUTPUT"
          echo "error_count=$ERROR_COUNT" >> "$GITHUB_OUTPUT"

      # Step 4: Create a GitHub issue with all errors
      - name: Create issue for detected errors
        if: steps.check.outputs.has_errors == 'true'
        id: issue
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          ERRORS=$(cat /tmp/errors.txt)
          TIMESTAMP=$(date -u +"%Y-%m-%d %H:%M UTC")
          ERROR_COUNT=${{ steps.check.outputs.error_count }}

          BODY="## Production Errors Detected

          The automated monitor found **$ERROR_COUNT errors** at **$TIMESTAMP**.

          All errors below come from the centralized log (Vercel Blob storage), which includes:
          - Vercel runtime errors (\`vercel:runtime\`)
          - Stripe webhook errors (\`webhook:stripe\`)
          - Resend email errors (\`webhook:resend\`)
          - Application errors (\`stripe:checkout\`, \`contact\`, \`ai:photos\`, etc.)

          ### Errors
          \`\`\`
          $ERRORS
          \`\`\`

          ### Status
          â³ Claude Haiku is analyzing these errors and attempting to create a fix PR...

          ---
          *This issue was created automatically by the [Error Monitor](https://github.com/${{ github.repository }}/actions/workflows/monitor.yml)*"

          ISSUE_URL=$(gh issue create \
            --title "ðŸš¨ Production errors detected - $TIMESTAMP" \
            --label "bug,automated" \
            --body "$BODY")

          echo "issue_url=$ISSUE_URL" >> "$GITHUB_OUTPUT"
          echo "Created issue: $ISSUE_URL"

      # Step 5: Install deps + let Claude analyze and fix
      - name: Install dependencies
        if: steps.check.outputs.has_errors == 'true'
        run: npm ci

      - name: Claude analyzes and fixes errors
        id: claude
        if: steps.check.outputs.has_errors == 'true'
        continue-on-error: true
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          npm i -g @anthropic-ai/claude-code

          ERRORS=$(cat /tmp/errors.txt)

          claude -p \
            --model claude-haiku \
            --allowedTools "Read,Edit,Bash(npm test),Bash(npm run test),Bash(git checkout -b *),Bash(git add *),Bash(git commit *),Bash(git push *),Bash(gh pr create *),Bash(git diff *),Bash(git status),Bash(git config *)" \
            "You are an automated error-fixing agent. Here are production errors from the centralized log:

          \`\`\`
          $ERRORS
          \`\`\`

          These errors come from various sources: vercel:runtime (Vercel function errors), webhook:stripe (Stripe payment/subscription issues), webhook:resend (email delivery issues), stripe:checkout (checkout flow), contact (contact form), ai:photos (photo analysis), geocode (geocoding).

          Please:
          1. Analyze these errors and identify the root cause
          2. Find the relevant source files in this repo
          3. Create a fix on a new branch (use format: fix/auto-$(date +%Y-%m-%d)-description)
          4. Run tests to verify the fix works
          5. Push the branch and create a PR with a clear description of what broke and how you fixed it

          If the errors are transient (network timeouts, rate limits, etc.) and not caused by our code, just log your analysis and do NOT create a PR." \
          2>&1 | tee /tmp/claude-output.txt

      # Step 6: Update issue with results
      - name: Update issue with results
        if: steps.check.outputs.has_errors == 'true'
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          CLAUDE_OUTPUT=$(cat /tmp/claude-output.txt 2>/dev/null || echo "No output captured")
          # Truncate if too long for a comment
          if [ ${#CLAUDE_OUTPUT} -gt 60000 ]; then
            CLAUDE_OUTPUT="${CLAUDE_OUTPUT:0:60000}... (truncated)"
          fi

          if [ "${{ steps.claude.outcome }}" == "success" ]; then
            gh issue comment "${{ steps.issue.outputs.issue_url }}" --body "$(cat <<EOF
          ## âœ… Claude Haiku Analysis Complete

          Claude analyzed the errors and took action. Check for a new PR linked to this issue.

          <details>
          <summary>Claude's full output</summary>

          \`\`\`
          $CLAUDE_OUTPUT
          \`\`\`

          </details>
          EOF
          )"
          else
            gh issue comment "${{ steps.issue.outputs.issue_url }}" --body "$(cat <<EOF
          ## âŒ Claude could not fix the errors automatically

          The automated fix attempt failed. Please investigate manually.

          <details>
          <summary>Claude's output</summary>

          \`\`\`
          $CLAUDE_OUTPUT
          \`\`\`

          </details>

          ---
          **Next steps:** Open Claude Code locally and investigate these production errors.
          EOF
          )"
          fi
